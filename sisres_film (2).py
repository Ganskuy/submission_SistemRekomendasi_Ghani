# -*- coding: utf-8 -*-
"""sisres_film.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-f2WsZorHmSy5nST0KL4O0Yc30_AI6d4

# Perbandingan Rekomendasi Film Berdasarkan Cosine Similarity dan Sumber Eksternal (CBR.com) untuk Film Avatar (2009)

## Business Understanding

### Problem Statement

Rumusan masalah pada proyek ini adalah :
- Dilansir dari Website Rotten Tomatoes tentang film dengan penghasilan tertinggi sepanjang masa, Avatar (2009) merupakan film no. 1 dengan penghasilan tertinggi, dengan metode Content-Based Filtering, film apakah yang akan direkomendasikan untuk film yang mirip dengan Avatar?
- Bagaimana perbedaan antara film yang direkomendasikan oleh model dengan film yang direkomendasikan oleh manusia?

### Goals

Tujuan dari menyelesaikan permasalahan diatas adalah :
- Mengetahui rekomendasi lain mengenai film yang mirip dengan Avatar (2009)
- Mengetahui seberapa akurat rekomendasi yang diberikan oleh model, jika dibandingkan dengan rekomendasi yang diberikan oleh manusia

### Solution Statement

- Menggunakan pendekatan Content-based Filtering untuk mengetahui film yang mirip dengan Avatar(2009)
- Menggunakan Metrik Evaluasi Precission@k untuk melihat perbandingan dari rekomendasi yang diberikan model, dengan rekomendasi yang diberikan oleh manusia

### Metodologi

Tujuan yang ingin dicapai dari proyek ini adalah, Mengetahui seberapa baik model machine learning dapat memberikan rekomendasi film dari data-data diberikan. Untuk mengetahuinya, kita perlu memberikan perbandingan dari rekomendasi yang diberikan oleh manusia dengan rekomendasi yang diberikan oleh model. Untuk itu, kita akan menggunakan Cosine Similarity dalam membuat Sistem Rekomendasi melalui pendekatan Item-based Filtering, dan menggunakan Metrik Evaluasi Precission@k dalam menilai seberapa baik model dalam memberikan rekomendasi film.

### Metrik

Untuk Metrik dalam mengukur Similarity, ada beberapa metrik yang dapat digunakan, diantaranya Cosine Similarity, Euclidean Distance, Jaccard Similarity, dan Pearson Correlation Coefficient adalah empat metrik populer untuk mengukur kesamaan atau jarak antar data. Cosine Similarity mengukur sudut antara dua vektor dalam ruang berdimensi tinggi, cocok untuk data teks atau rating karena memperhatikan arah, bukan besaran. Euclidean Distance menghitung jarak lurus antara dua titik, umum digunakan untuk data numerik dan posisi. Jaccard Similarity mengukur seberapa besar kesamaan antara dua himpunan dibandingkan total elemen uniknya, ideal untuk data kategorikal atau biner seperti genre film. Sementara itu, Pearson Correlation Coefficient mengukur kekuatan dan arah hubungan linear antara dua variabel, sering digunakan dalam sistem rekomendasi berbasis rating untuk memahami pola preferensi pengguna. Namun pada proyek kali ini, kita akan menggunakan Metrik Evaluasi Cosine Similarity karena mampu mengukur kemiripan antar film berdasarkan informasi seperti genre, sutradara, dan penulis yang dapat diubah menjadi representasi vektor. Metode ini fokus pada arah vektor, bukan besarannya, sehingga efektif untuk data teks yang bersifat sparse. Dalam sistem rekomendasi berbasis item, cosine similarity membantu menemukan film yang paling mirip secara konten dengan film tertentu secara efisien dan akurat.

## Data Understanding

### Data Understanding

Data Understanding merupakan proses pada analisia data yang bertujuan untuk memahami dataset secara mendalam sebelum melakukan analisis lebih lanjut.

### Data Loading

Data Loading merupakan proses memuat dataset yang akan digunakan untuk membangun model machine learning

### Informasi Dataset

| **Jenis**     | **Keterangan**                                                                                       |
|---------------|------------------------------------------------------------------------------------------------------|
| **Title**     | 16000+ Movies 1910-2024 (Metacritic)                                                                 |
| **Source**    | [Kaggle](https://www.kaggle.com/datasets/kashifsahil/16000-movies-1910-2024-metacritic)              |
| **Owner**     | [KashifSahil](https://www.kaggle.com/kashifsahil)                                                    |
| **License**   | Database: Open Database, Contents                                                                    |
| **Visibility**| Publik                                                                                               |
| **Tags**      | Movies and TV Shows, Arts and Entertainment, Data Analytics, Data Visualization, Recommender System  |
| **Usability** | 10.00                                                                                                |
"""

import pandas as pd
df=pd.read_csv('16k_Movies.csv')
df

"""Dataset yang digunakan memiliki total 10 kolom dengan 16290 baris"""

df[df['Title'] == 'Avatar']

"""Terlihat bahwa dataset tersebut memiliki film dengan judul Avatar yang rilis pada tahun 2009, maka dataset ini bisa digunakan dalam menjawab rumusan masalah kita

## Exploratory Data Analysis (EDA)
"""

df.info()

"""dari otuptu diatas dapat dilihat bahwa:
- Unnamed: 0 memiliki 16290 data dengan tipe integer
- Title memiliki 16290 data bertipe object
- Release Date memiliki 16290 data bertipe object (seharusnya date time)
- Rating memiliki 12846 data bertipe float
- No of Persons Voted berisi 12829 data bertipe object (seharusnya integer)
- Directed by berisi 16283 data bertipe object
- Written by berisi 15327 data bertipe object
- Duration berisi 16277 data bertipe object
- Genres berisi 16285 data bertipe object

terlihat juga ada beberapa kolom yang berjumlah tidak sama, ini artinya terdapat missing value, maka kita akan mengatasinya pada proses PreProcessing, selanjutnya kita akan melihat data unik pada Genres, Directed by, dan Written by
"""

print('Banyak genre: ', len(df.Genres.unique()))
print('Banyak data: ', len(df['Written by'].unique()))
print('Banyak data: ', len(df['Directed by'].unique()))

"""dapat disimpulkan bahwa, dalam dataset terdapat 1664 data dengan genre berbeda, 11788 data dengan penulis berbeda, dan 7380 data dengan sutradara yang berbeda."""

print(df['Rating'].describe())

"""Terlihat bahwa rating memiliki nilai maksimum 10, dengan rata-rata 6.6"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(df['Rating'], bins=20)
plt.title('Distribusi Rating Film')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.show()

"""terlihat bahwa pada fitur rating, film dengan rating 7 adalah frekuensi terbanyak

### Mengetahui jumlah missing value pada tiap kolom
"""

df.isna().sum()

"""terlihat bahwa terdapat beberapa kolom yang berisi nilai NaN, yaitu pada kolom:
- Rating
- No of Persons Voted
- Directed by
- Written by
- Duration
- Genres

namun sebelum drop kolom-kolom yang memiliki nilai NaN, kita akan drop terlebih dahulu kolom yang tidak akan digunakan pada model, yaitu Duration, Release Date, No of Persons Voted, dan Unnamed: 0, alasannya antara lain:
- Duration hanya berisi durasi dari film tersebut
- Release Date berisi informasi mengenai kapan film tersebut rilis
- Unnamed: 0 hanya berisi nomor kolom
- No of Persons Voted : berisi jumlah orang yang sudah vote

### Mengetahui jumlah data duplikat
"""

df['Title'].duplicated().sum()

"""Judul merupakan data yang isinya tidak mungkin sama, dan Terlihat bahwa terdapat 1275 data duplikat pada kolom Title, oleh karena itu kita akan drop kolom-kolom tersebut

## Data Preprocessing

### Drop kolom yang tidak relevan
"""

df = df.drop(['Unnamed: 0', 'Release Date', 'No of Persons Voted', 'Duration'], axis=1)
df

"""### Drop kolom yang berisi missing value"""

df=df.dropna()
df

"""### Drop Kolom yang Berisi Data Duplikat"""

df = df.drop_duplicates('Title')
df

"""Terlihat bahwa jumlah baris telah berkurang menjadi 11076 baris dengan 6 kolom

### Text Preprocessing

#### Menghilangkan \n pada teks
"""

df_clean=df.copy()
df_clean = df_clean.replace('\n', ' ', regex=True)
df_clean

"""terlihat bahwa penulisan "Dinesh D'Souza, \n \n Bruce Schooley" pada kolom Directed bysudah menjadi "Dinesh D'Souza, Bruce Schooley"

#### Menghilangkan tanda baca, dan case folding
"""

kolom_teks = ['Description', 'Directed by', 'Written by']

df_clean[kolom_teks] = df_clean[kolom_teks].apply(
    lambda col: col
        .str.replace(r'[^\w\s]', '', regex=True)
        .str.lower()
        .str.strip()
)

df_clean['Genres'] = (
    df_clean['Genres']
        .str.replace(r'[^\w\s]', ' ', regex=True)
        .str.lower()
        .str.strip()
)

"""Disini saya menghilangkan tanda baca dan melakukan case folding pada fitur Description, Directed by, dan Written by, kemudian melakukan juga proses yang sama pada Genres namun mengganti tanda baca menjadi spasi

#### Lemmatization dan stop word removal pada fitur Description
"""

import spacy

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Proses kolom 'Description'
df_clean['Description'] = df_clean['Description'].apply(
    lambda x: ' '.join([
        token.lemma_ for token in nlp(x)
        if not token.is_stop and not token.is_punct and not token.is_space
    ])
)

"""Disini yang saya lakukan adalah:
- Melakukan Lemmatization untuk mengembalikan kata-kata yang ada menjadi bentuk asal
- Melakukan Stop Word Remocal untuk meningkatkan akurasi

#### Menggabungkan Description, Directed by, Written by, dan Genres kedalam 1 kolom bernama info
"""

data = df_clean
data['info'] = data['Genres'] + ' ' + data['Directed by'] + ' ' + data['Written by'] + ' ' + data['Description']
data.drop(['Genres', 'Directed by', 'Written by', 'Description', 'Rating'], axis=1, inplace=True)
data.head()

"""karena fitur Description, Directed by, Written by, dan Genres sudah digabung menjadi satu string kedalam 'fitur', maka kita bisa drop kolom-kolom tersebut. Kemudian untuk fitur Rating, kita drop juga karena fitur ini tidak akan digunakan pada Content-based filtering

### Ekstraksi Fitur dan Pembobotan Term Menggunakan TF-IDF
"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(data['info'])
tfidf_matrix.shape

"""Pada proses ini, berikut adalah hal-hal yang dilakukan:
- Memanggil class TfidfVectorizer pada modul Scikit Learn
- Mengubah data pada kolom info menjadi array
"""

tfidf_matrix.todense()

"""Disini saya mengubah tfidf_matrix kedalam bentuk matrix dengan fungsi todense()"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=vectorizer.get_feature_names_out(),
    index=data.Title
).sample(22, axis=1).sample(10, axis=0)

"""Pada proses diatas, yang dilakukan adalah:
- Membuat dataframe untuk melihat tf-idf matrix
- Kolom diisi dengan info
- Baris diisi dengan nama film

## Model Development dengan Content-based Filtering

### Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Pada proses ini, kita menghitung cosine similarity pada tfidf_matrix"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['Title'], columns=data['Title'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""pada proses diatas, hal yang dilakukan adalah:
- Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama Film
- Melihat similarity matrix pada setiap film
"""

def film_recommendations(nama_film, similarity_data=cosine_sim_df, items=data[['Title', 'info']], k=10):
    index = similarity_data.loc[:, nama_film].to_numpy().argpartition(range(-1, -k-1, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(nama_film, errors='ignore')

    # Ambil skor similarity-nya
    similarity_scores = similarity_data.loc[closest, nama_film].values

    # Gabungkan dengan info film
    rekomendasi_df = pd.DataFrame(closest, columns=["Title"])
    rekomendasi_df["Similarity"] = similarity_scores

    return rekomendasi_df.merge(items, on="Title").sort_values(by="Similarity", ascending=False).head(k)

"""pada proses ini, yang dilakukan adalah:
- Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
- Dataframe diubah menjadi numpy
- Urutan akan turun dari -1 sampai -k, dengan step -1
- Mengambil data dengan similarity terbesar dari index yang ada
- Drop nama_film agar nama film yang dicari tidak muncul dalam daftar rekomendasi
- menggunakan k=10, artinya model akan memberikan rekomendasi sebanyak 10 film
"""

data[data.Title.eq('Avatar')]

film_recommendations('Avatar')

"""Hasil diatas merupakan rekomendasi yang diberikan oleh model, kemudian kita akan menelusuri seberapa akuratnya rekomendasi yang diberikan jika kita bandingkan dengan Human Behaviour"""

import pandas as pd

ground_truth = {
    "Avatar": [
        "Annihilation",
        "Inception",
        "Interstellar",
        "Avatar: The Way of Water",
        "Prometheus",
        "Pocahontas",
        "Oblivion",
        "Atlantis: The Lost Empire",
        "Valerian and the City of a Thousand Planets",
        "Stargate",
        "Dune"
    ]
}

def precision_at_k(recommended, relevant, k):
    recommended_at_k = recommended[:k]
    relevant_set = set(relevant)
    hits = sum([1 for item in recommended_at_k if item in relevant_set])
    return hits / k

# Ambil hasil rekomendasi untuk film "Avatar"
rekomendasi = film_recommendations("Avatar")["Title"].tolist()

# Hitung precision@k untuk k = 1 hingga 10
results = []
for k in range(1, 11):
    prec = precision_at_k(rekomendasi, ground_truth["Avatar"], k)
    results.append({'k': k, 'Precision@k': prec})

# Buat DataFrame
precision_df = pd.DataFrame(results)

# Hitung Mean Average Precision@K
map_k = precision_df["Precision@k"].mean()

# Tampilkan hasil
print("==================================== Hasil Evaluasi =========================================\n")
print(precision_df.to_string(index=False))
print(f"\nMean Average Precision@10 (MAP@10): {map_k:.4f}")

"""Disini kita menggunakan Metrik Evaluasi Presiccion@k, Metrik ini mengukur seberapa relevan item-item yang direkomendasikan di antara k item teratas yang diberikan oleh sistem. pada variabel ground_truth saya mengisi film-film yang mirip dengan Avatar (2009) berdasarkan informasi yang saya dapatkan dari web cbr.com tentang "10 Movies To Watch If You Love James Cameron's Avatar." Terlihat bahwa hasil evaluasi menunjukan berbagai perbedaan pada berbagai nilai k, dengan nilai tertinggi pada k=1 dengan nilai 1, dan dilanjut dengan k=2 dengan nilai 0.5, dan akhirnya pada k=10 nilainya adalah 0.1, kita dapat menyimpulkan pada k=10 ini bahwa dari 10 film yang direkomendasikan, hanya ada 1 film yang paling revelan. Kemudian dari hasil Mean Average Precission, didapati hasil sebesar 0.29 yang menunjukkan bahwa, secara umum, sistem hanya berhasil menghasilkan relevansi sebesar ~29% dari 10 item teratas. Hal ini terjadi karena adanya perbedaan cara berpikir mesin dan manusia, mesin memutuskan sesuatu berdasarkan data, sedangkan film-film yang saya masukkan pada variabel ground_truth merupakan hasil opini orang lain. Namun dari top-N Recommendation yang ditampilkan, saya rasa rekomendasi yang diberikan cukup relevan jika menilai dari data, karena beberapa film yang direkomendasikan memiliki beberapa kesamaan terutama dari Genre Action, Adventure dan Romance, mengingat film avatar ini memang mengisahkan tentang petualangan Jake Sully yang rela meninggalkan kemanusiaannya untuk hidup sebagai makhluk dari planet lain (Alien) karena menemukan wanita yang dicintainya yang berasal dari ras dari planet tersebut. Namun satu hal yang saya sadari dari rekomendasi yang diberikan, model tidak memberikan rekomendasi film dengan genre Science Fiction lain, padahal menurut saya Science Fiction merupakan salah satu Genre yang membangun citra dari film Avatar (2009) ini."""